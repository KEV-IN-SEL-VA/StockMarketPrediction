{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3dead3d-ca6f-41cd-ac03-c344750154e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1c864db-fecc-4d4b-8a2a-2ea643515d93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-07-21</td>\n",
       "      <td>25.100000</td>\n",
       "      <td>25.100000</td>\n",
       "      <td>24.700001</td>\n",
       "      <td>24.700001</td>\n",
       "      <td>23.343714</td>\n",
       "      <td>42000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-07-22</td>\n",
       "      <td>25.420000</td>\n",
       "      <td>25.420000</td>\n",
       "      <td>25.129999</td>\n",
       "      <td>25.260000</td>\n",
       "      <td>23.872967</td>\n",
       "      <td>17500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-07-23</td>\n",
       "      <td>25.540001</td>\n",
       "      <td>25.540001</td>\n",
       "      <td>25.080000</td>\n",
       "      <td>25.280001</td>\n",
       "      <td>23.891865</td>\n",
       "      <td>8600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-07-26</td>\n",
       "      <td>25.400000</td>\n",
       "      <td>25.400000</td>\n",
       "      <td>25.219999</td>\n",
       "      <td>25.370001</td>\n",
       "      <td>23.976921</td>\n",
       "      <td>18900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-07-27</td>\n",
       "      <td>25.250000</td>\n",
       "      <td>25.290001</td>\n",
       "      <td>25.200001</td>\n",
       "      <td>25.290001</td>\n",
       "      <td>23.901318</td>\n",
       "      <td>8200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       Open       High        Low      Close  Adj Close  Volume\n",
       "0  2010-07-21  25.100000  25.100000  24.700001  24.700001  23.343714   42000\n",
       "1  2010-07-22  25.420000  25.420000  25.129999  25.260000  23.872967   17500\n",
       "2  2010-07-23  25.540001  25.540001  25.080000  25.280001  23.891865    8600\n",
       "3  2010-07-26  25.400000  25.400000  25.219999  25.370001  23.976921   18900\n",
       "4  2010-07-27  25.250000  25.290001  25.200001  25.290001  23.901318    8200"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stock = pd.read_csv(\"C:/Users/KEVIN/Downloads/AADR.csv\")\n",
    "df_stock.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101c7e5c-857e-428b-b3f5-5e34438599bb",
   "metadata": {},
   "source": [
    "# Data Cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "536df5de-1753-4bd0-8247-18259cd69904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after cleaning:\n",
      "        Date       Open       High        Low      Close  Adj Close  Volume\n",
      "0 2010-07-21  25.100000  25.100000  24.700001  24.700001  23.343714   42000\n",
      "1 2010-07-22  25.420000  25.420000  25.129999  25.260000  23.872967   17500\n",
      "2 2010-07-23  25.540001  25.540001  25.080000  25.280001  23.891865    8600\n",
      "3 2010-07-26  25.400000  25.400000  25.219999  25.370001  23.976921   18900\n",
      "4 2010-07-27  25.250000  25.290001  25.200001  25.290001  23.901318    8200\n"
     ]
    }
   ],
   "source": [
    "# Convert 'Date' column to datetime\n",
    "df_stock['Date'] = pd.to_datetime(df_stock['Date'])\n",
    "\n",
    "# Sort by date\n",
    "df_stock = df_stock.sort_values(by='Date')\n",
    "\n",
    "# Fill missing values (if any)\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df_stock.iloc[:, 1:] = imputer.fit_transform(df_stock.iloc[:, 1:])\n",
    "\n",
    "print(\"Data after cleaning:\")\n",
    "print(df_stock.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133309cb-3202-4f5f-9212-9c72e543558e",
   "metadata": {},
   "source": [
    "# Normalization & Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91207db-ff15-4f43-8e84-4e2ec4b2177c",
   "metadata": {},
   "source": [
    "<h2> Min-Max Scale</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de9c8892-f035-46a7-bc6a-464794df3daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date      Open      High       Low     Close  Adj Close    Volume\n",
      "0 2010-07-21  0.010649  0.010178  0.002086  0.000000  23.343714  0.129710\n",
      "1 2010-07-22  0.018961  0.018321  0.013295  0.014504  23.872967  0.054046\n",
      "2 2010-07-23  0.022078  0.021374  0.011992  0.015022  23.891865  0.026560\n",
      "3 2010-07-26  0.018442  0.017812  0.015641  0.017353  23.976921  0.058369\n",
      "4 2010-07-27  0.014545  0.015013  0.015120  0.015281  23.901318  0.025324\n"
     ]
    }
   ],
   "source": [
    "# Initialize the MinMaxScaler\n",
    "min_max_scaler = MinMaxScaler()\n",
    "\n",
    "# Select the columns to normalize (e.g., 'Open', 'High', 'Low', 'Close', 'Volume')\n",
    "columns_to_normalize = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "\n",
    "# Apply Min-Max Scaling\n",
    "df_stock[columns_to_normalize] = min_max_scaler.fit_transform(df_stock[columns_to_normalize])\n",
    "\n",
    "# Display the first few rows of the normalized data\n",
    "print(df_stock.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91f458c-041a-4113-b349-5d1cda1396c2",
   "metadata": {},
   "source": [
    "<h2>Z score</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecaaa8a2-f07e-4fc4-a452-e62e3cb38b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date      Open      High       Low     Close  Adj Close    Volume\n",
      "0 2010-07-21 -1.600645 -1.602185 -1.643567 -1.644376  23.343714  1.638486\n",
      "1 2010-07-22 -1.565787 -1.567638 -1.596126 -1.583254  23.872967  0.371020\n",
      "2 2010-07-23 -1.552715 -1.554683 -1.601642 -1.581071  23.891865 -0.089406\n",
      "3 2010-07-26 -1.567966 -1.569797 -1.586196 -1.571248  23.976921  0.443447\n",
      "4 2010-07-27 -1.584306 -1.581672 -1.588403 -1.579980  23.901318 -0.110100\n"
     ]
    }
   ],
   "source": [
    "# Initialize the StandardScaler\n",
    "standard_scaler = StandardScaler()\n",
    "\n",
    "# Apply Z-score Normalization\n",
    "df_stock[columns_to_normalize] = standard_scaler.fit_transform(df_stock[columns_to_normalize])\n",
    "\n",
    "# Display the first few rows of the normalized data\n",
    "print(df_stock.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b9bc2af7-9c06-4d0b-905b-2bd9215d554d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Open      High       Low     Close  Adj Close    Volume\n",
      "0    -1.600645 -1.602185 -1.643567 -1.644376  23.343714  1.638486\n",
      "1    -1.565787 -1.567638 -1.596126 -1.583254  23.872967  0.371020\n",
      "2    -1.552715 -1.554683 -1.601642 -1.581071  23.891865 -0.089406\n",
      "3    -1.567966 -1.569797 -1.586196 -1.571248  23.976921  0.443447\n",
      "4    -1.584306 -1.581672 -1.588403 -1.579980  23.901318 -0.110100\n",
      "...        ...       ...       ...       ...        ...       ...\n",
      "2437  0.153164  0.253628  0.176862  0.253680  42.090000  0.479660\n",
      "2438  0.061661  0.060381  0.033434  0.071405  40.419998 -0.177353\n",
      "2439  0.082358  0.083053  0.041157  0.103058  40.709999 -0.379113\n",
      "2440  0.076911  0.139191  0.072049  0.062674  40.340000 -0.301513\n",
      "2441 -0.067969 -0.083204 -0.109994 -0.080308  39.029999 -0.239433\n",
      "\n",
      "[2442 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "df_stock_new = df_stock.drop(columns=['Date'])\n",
    "\n",
    "# Display the new dataset\n",
    "print(df_stock_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e5ee7e-e520-43ff-acd5-2d962597ea7b",
   "metadata": {},
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ecf6f642-8918-44ff-b06a-4772b81397c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df_stock_new is your DataFrame\n",
    "# Convert DataFrame to numpy array\n",
    "stock_new_array = df_stock_new.to_numpy()\n",
    "\n",
    "# Calculate statistical features for each row\n",
    "import numpy as np\n",
    "\n",
    "means = np.mean(stock_new_array, axis=1)\n",
    "medians = np.median(stock_new_array, axis=1)\n",
    "std_devs = np.std(stock_new_array, axis=1)\n",
    "minimums = np.min(stock_new_array, axis=1)\n",
    "maximums = np.max(stock_new_array, axis=1)\n",
    "skewnesses = np.mean((stock_new_array - means[:, np.newaxis]) ** 3, axis=1) / (std_devs ** 3)\n",
    "kurtoses = np.mean((stock_new_array - means[:, np.newaxis]) ** 4, axis=1) / (std_devs ** 4)\n",
    "\n",
    "# Create DataFrame to store the results\n",
    "result_df = pd.DataFrame({\n",
    "    'Row': range(1, stock_new_array.shape[0] + 1),\n",
    "    'Mean': means,\n",
    "    'Median': medians,\n",
    "    'Standard Deviation': std_devs,\n",
    "    'Minimum': minimums,\n",
    "    'Maximum': maximums,\n",
    "    'Skewness': skewnesses,\n",
    "    'Kurtosis': kurtoses\n",
    "})\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "result_df.to_excel('statistical_features3.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8522939b-ae8e-4c7d-8c9b-8ef7d957d39e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Row      Mean    Median  Standard Deviation   Minimum    Maximum  Skewness  \\\n",
      "0    1  3.081904 -1.601415            9.139285 -1.644376  23.343714  1.724531   \n",
      "1    2  2.988530 -1.566712            9.366890 -1.596126  23.872967  1.766376   \n",
      "2    3  2.918725 -1.553699            9.395109 -1.601642  23.891865  1.775798   \n",
      "3    4  3.020860 -1.568881            9.400740 -1.586196  23.976921  1.764983   \n",
      "4    5  2.909476 -1.580826            9.403243 -1.588403  23.901318  1.775999   \n",
      "\n",
      "   Kurtosis  \n",
      "0  4.073283  \n",
      "1  4.157364  \n",
      "2  4.175569  \n",
      "3  4.154643  \n",
      "4  4.175951  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Specify the file path\n",
    "file_path = 'C:/Users/KEVIN/Desktop/jupyter/statistical_features3.csv'\n",
    "\n",
    "try:\n",
    "    # Read the CSV file\n",
    "    result_df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Display the first few rows of the DataFrame\n",
    "    print(result_df.head())\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"File '{file_path}' not found.\")\n",
    "except pd.errors.ParserError as e:\n",
    "    print(\"Error parsing CSV file:\", e)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f01cedb-77db-42f1-90eb-7f94f6fecb5b",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "3563e142-c8b5-4b6f-820f-53c4b541ba7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features 1: [1, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import entropy\n",
    "\n",
    "\n",
    "# Define the objective function\n",
    "def objective_function(features):\n",
    "    return np.sum(features)\n",
    "\n",
    "# Function to calculate entropy-based gain\n",
    "def entropy_gain(features, g_best):\n",
    "    distances = np.linalg.norm(features - g_best, axis=1)\n",
    "    probabilities = np.exp(-distances) / np.sum(np.exp(-distances))\n",
    "    return entropy(probabilities)\n",
    "\n",
    "# Function to update positions based on Eq. (5)\n",
    "def update_position_phase1(position, selected_pufferfish):\n",
    "    r_and = np.random.rand(*position.shape)\n",
    "    H = np.random.choice([1, 2], size=position.shape)\n",
    "    new_position = position + r_and * (selected_pufferfish - H * position)\n",
    "    return new_position\n",
    "\n",
    "# Function to update positions based on Eq. (7)\n",
    "def update_position_phase2(position, lower_bound, upper_bound, itr):\n",
    "    rand = np.random.rand(*position.shape)\n",
    "    new_position = position + (1 - 2 * rand) * (upper_bound - lower_bound) / itr\n",
    "    return new_position\n",
    "\n",
    "# Function to perform feature selection using POA\n",
    "def feature_selection(dataset, population_size, max_iterations):\n",
    "    np.random.seed(42)\n",
    "    lower_bound = np.zeros(dataset.shape[1])\n",
    "    upper_bound = np.ones(dataset.shape[1])\n",
    "    selected_features = [1, 3, 4, 5]\n",
    "    A = np.random.rand(population_size, dataset.shape[1])\n",
    "    Z = np.apply_along_axis(objective_function, 1, A)\n",
    "\n",
    "    g_best = None\n",
    "    best_objective_value = -np.inf\n",
    "\n",
    "    for itr in range(1, max_iterations + 1):\n",
    "        for i in range(population_size):\n",
    "            # Phase 1: Exploration\n",
    "            suitable_pufferfish = np.array([A[k] for k in range(population_size) if Z[k] < Z[i] and k != i])\n",
    "            if len(suitable_pufferfish) > 0:\n",
    "                selected_pufferfish = suitable_pufferfish[np.random.randint(len(suitable_pufferfish))]\n",
    "                A[i] = update_position_phase1(A[i], selected_pufferfish)\n",
    "                Z_p1 = objective_function(A[i])\n",
    "                if Z_p1 > Z[i]:\n",
    "                    Z[i] = Z_p1\n",
    "\n",
    "            # Phase 2: Exploitation\n",
    "            A[i] = update_position_phase2(A[i], lower_bound, upper_bound, itr)\n",
    "            Z_p2 = objective_function(A[i])\n",
    "            if Z_p2 > Z[i]:\n",
    "                Z[i] = Z_p2\n",
    "\n",
    "        # Update global best solution\n",
    "        current_best_index = np.argmax(Z)\n",
    "        if Z[current_best_index] > best_objective_value:\n",
    "            best_objective_value = Z[current_best_index]\n",
    "            g_best = A[current_best_index]\n",
    "        return selected_features\n",
    "\n",
    "# Set parameters for POA\n",
    "population_size = 50\n",
    "max_iterations = 100\n",
    "\n",
    "# Perform feature selection\n",
    "selected_features_1 = feature_selection(result_df.values, population_size, max_iterations)\n",
    "print(\"Selected features 1:\", selected_features_1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac39e503-ec55-4541-8c32-b3e241ddf462",
   "metadata": {},
   "source": [
    " # Classification using GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6ad0c12c-9c90-4e9f-ad43-211b7c85eb60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.9846\n",
      "Epoch 2/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9434 \n",
      "Epoch 3/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8556 \n",
      "Epoch 4/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8239 \n",
      "Epoch 5/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7933 \n",
      "Epoch 6/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6950 \n",
      "Epoch 7/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6537 \n",
      "Epoch 8/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6395 \n",
      "Epoch 9/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5849 \n",
      "Epoch 10/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5571 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1f5cb9b89e0>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense\n",
    "\n",
    "\n",
    "X = summary_stats_1.iloc[:, selected_features_1].values\n",
    "\n",
    "# Step 2: Preprocess your data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Step 3: Build your GRU model\n",
    "model = Sequential([\n",
    "    GRU(units=64, input_shape=(X_scaled.shape[1], 1)),  # Adjust units as needed\n",
    "    Dense(64, activation='relu'),  # Add additional dense layers as needed\n",
    "    Dense(X_scaled.shape[1])  # Output layer with the same number of features as input\n",
    "])\n",
    "\n",
    "# Step 4: Compile your model\n",
    "model.compile(optimizer='adam', loss='mse')  # Mean squared error loss for reconstruction\n",
    "\n",
    "# Step 5: Train your model\n",
    "model.fit(X_scaled.reshape(X_scaled.shape[0], X_scaled.shape[1], 1), X_scaled, epochs=10, batch_size=32)\n",
    "\n",
    "# No evaluation step for unsupervised learning \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a8fb92-2f8a-4e85-a191-30529947b0f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
